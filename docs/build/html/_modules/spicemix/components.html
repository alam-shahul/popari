
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>spicemix.components &#8212; SpiceMixPlus 0.0.1 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css" type="text/css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">SpiceMixPlus 0.0.1 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for spicemix.components</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">import</span> <span class="nn">logging</span><span class="o">,</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>

<span class="kn">import</span> <span class="nn">anndata</span> <span class="k">as</span> <span class="nn">ad</span>
<span class="kn">import</span> <span class="nn">scanpy</span> <span class="k">as</span> <span class="nn">sc</span>
<span class="kn">import</span> <span class="nn">squidpy</span> <span class="k">as</span> <span class="nn">sq</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">spicemix.sample_for_integral</span> <span class="kn">import</span> <span class="n">integrate_of_exponential_over_simplex</span>
<span class="kn">from</span> <span class="nn">spicemix.util</span> <span class="kn">import</span> <span class="n">NesterovGD</span><span class="p">,</span> <span class="n">IndependentSet</span><span class="p">,</span> <span class="n">project2simplex</span><span class="p">,</span> <span class="n">project_M</span><span class="p">,</span> <span class="n">get_datetime</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">MultiheadAttention</span>

<div class="viewcode-block" id="SpiceMixDataset"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpiceMixDataset">[docs]</a><span class="k">class</span> <span class="nc">SpiceMixDataset</span><span class="p">(</span><span class="n">ad</span><span class="o">.</span><span class="n">AnnData</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around AnnData object. Allows for preprocessing of dataset for SpiceMix.</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">replicate_name</span><span class="p">,</span> <span class="n">coordinates_key</span><span class="o">=</span><span class="s2">&quot;spatial&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
            <span class="n">obsp</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obsp</span><span class="p">,</span>
            <span class="n">obsm</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obsm</span><span class="p">,</span> 
            <span class="n">var</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">var</span><span class="p">,</span> 
            <span class="n">varp</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">varp</span><span class="p">,</span>
            <span class="n">uns</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">uns</span>
        <span class="p">)</span>
      
        <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_key</span> <span class="o">=</span> <span class="n">coordinates_key</span> 
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsm</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dataset must include spatial coordinates.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">replicate_name</span><span class="si">}</span><span class="s2">&quot;</span>

<div class="viewcode-block" id="SpiceMixDataset.compute_spatial_neighbors"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpiceMixDataset.compute_spatial_neighbors">[docs]</a>    <span class="k">def</span> <span class="nf">compute_spatial_neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute neighbor graph based on spatial coordinates.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sq</span><span class="o">.</span><span class="n">gr</span><span class="o">.</span><span class="n">spatial_neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coord_type</span><span class="o">=</span><span class="s2">&quot;generic&quot;</span><span class="p">,</span> <span class="n">delaunay</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">distance_matrix</span><span class="p">,</span> <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;spatial_distances&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;spatial_connectivities&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;spatial_connectivities&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SpiceMixDataset</span><span class="o">.</span><span class="n">remove_connectivity_artifacts</span><span class="p">(</span><span class="n">distance_matrix</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;adjacency_matrix&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;spatial_connectivities&quot;</span><span class="p">]</span>
        
        <span class="n">num_cells</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;adjacency_matrix&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">adjacency_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_cells</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;adjacency_matrix&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()):</span>
            <span class="n">adjacency_list</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency_list</span></div>

<div class="viewcode-block" id="SpiceMixDataset.remove_connectivity_artifacts"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpiceMixDataset.remove_connectivity_artifacts">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">remove_connectivity_artifacts</span><span class="p">(</span><span class="n">sparse_distance_matrix</span><span class="p">,</span> <span class="n">sparse_adjacency_matrix</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">94.5</span><span class="p">):</span>
        <span class="n">dense_distances</span> <span class="o">=</span> <span class="n">sparse_distance_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">sparse_distance_matrix</span><span class="o">.</span><span class="n">data</span>
        <span class="n">cutoff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">dense_distances</span> <span class="o">&lt;</span> <span class="n">cutoff</span>
    
        <span class="n">sparse_adjacency_matrix</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sparse_adjacency_matrix</span><span class="o">.</span><span class="n">eliminate_zeros</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">sparse_adjacency_matrix</span></div>

<div class="viewcode-block" id="SpiceMixDataset.plot_metagene_embedding"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpiceMixDataset.plot_metagene_embedding">[docs]</a>    <span class="k">def</span> <span class="nf">plot_metagene_embedding</span><span class="p">(</span><span class="n">metagene_index</span><span class="p">,</span> <span class="o">**</span><span class="n">scatterplot_kwargs</span><span class="p">):</span>
        <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;spatial&quot;</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">points</span><span class="o">.</span><span class="n">T</span>
        <span class="n">metagene</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">][:,</span> <span class="n">metagene_index</span><span class="p">]</span>
    
        <span class="n">biased_batch_effect</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="n">y</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Metagene </span><span class="si">{</span><span class="n">metagene_index</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">metagene</span><span class="p">})</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">biased_batch_effect</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;spatial_metagene&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">scatterplot_kwargs</span><span class="p">)</span></div></div>
 
<div class="viewcode-block" id="EmbeddingOptimizer"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingOptimizer">[docs]</a><span class="k">class</span> <span class="nc">EmbeddingOptimizer</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Optimizer and state for SpiceMix embeddings.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">initial_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ys</span> <span class="o">=</span> <span class="n">Ys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span> <span class="o">=</span> <span class="n">initial_context</span> <span class="k">if</span> <span class="n">initial_context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_state</span> <span class="o">=</span> <span class="n">EmbeddingState</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>

<div class="viewcode-block" id="EmbeddingOptimizer.link"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingOptimizer.link">[docs]</a>    <span class="k">def</span> <span class="nf">link</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span> <span class="o">=</span> <span class="n">parameter_optimizer</span></div>

<div class="viewcode-block" id="EmbeddingOptimizer.update_embeddings"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingOptimizer.update_embeddings">[docs]</a>    <span class="k">def</span> <span class="nf">update_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_neighbors</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update SpiceMixPlus embeddings according to optimization scheme.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">get_datetime</span><span class="p">()</span><span class="si">}</span><span class="s1">Updating latent states&#39;</span><span class="p">)</span>

        <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span>  <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
            <span class="n">is_spatial_replicate</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;adjacency_list&quot;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">sigma_yx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span><span class="o">.</span><span class="n">sigma_yxs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ys</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
            <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
            <span class="n">prior_x_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span><span class="o">.</span><span class="n">prior_x_modes</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
            <span class="n">prior_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span><span class="o">.</span><span class="n">prior_xs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_spatial_replicate</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">use_neighbors</span><span class="p">:</span>
                <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">][:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_weight_wonbr</span><span class="p">(</span>
                    <span class="n">Y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sigma_yx</span><span class="p">,</span> <span class="n">prior_x_mode</span><span class="p">,</span> <span class="n">prior_x</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">][:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_weight_wnbr</span><span class="p">(</span>
                    <span class="n">Y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sigma_yx</span><span class="p">,</span> <span class="n">prior_x_mode</span><span class="p">,</span> <span class="n">prior_x</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>

            <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingOptimizer.estimate_weight_wonbr"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingOptimizer.estimate_weight_wonbr">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">estimate_weight_wonbr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sigma_yx</span><span class="p">,</span> <span class="n">prior_x_mode</span><span class="p">,</span> <span class="n">prior_x</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">update_alg</span><span class="o">=</span><span class="s1">&#39;gd&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate weights without spatial information - equivalent to vanilla NMF.</span>
<span class="sd">   </span>
<span class="sd">        Optimizes the follwing objective with respect to hidden state X:</span>

<span class="sd">        min 1/2σ^2 || Y - X MT ||_2^2 + lam || X ||_1</span>
<span class="sd">        grad = X MT M / σ^2 - Y MT / σ^2 + lam</span>
<span class="sd">    </span>
<span class="sd">        TODO: use (projected) Nesterov GD. not urgent</span>

<span class="sd">        Args:</span>
<span class="sd">            Y (torch.Tensor):</span>
<span class="sd">        &quot;&quot;&quot;</span>
    
        <span class="c1"># Precomputing quantities </span>
        <span class="n">MTM</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">M</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">YM</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">@</span> <span class="n">M</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">Ynorm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">step_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">MTM</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">loss_prev</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    
        <span class="k">def</span> <span class="nf">multiplicative_update</span><span class="p">(</span><span class="n">X_prev</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            TODO:UNTESTED</span>
<span class="sd">    </span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X_prev</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">clipped_X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">YM</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">Ynorm</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">numerator</span> <span class="o">=</span> <span class="n">YM</span>
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span>
            <span class="k">if</span> <span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span><span class="p">:</span>
                <span class="c1"># see sklearn.decomposition.NMF</span>
                <span class="n">loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">denominator</span> <span class="o">+=</span> <span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">assert</span> <span class="n">loss</span> <span class="o">&lt;=</span> <span class="n">loss_prev</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span> <span class="p">(</span><span class="n">loss_prev</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">loss</span><span class="p">)</span>
            <span class="n">multiplicative_factor</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
            <span class="n">X</span> <span class="o">*=</span> <span class="n">multiplicative_factor</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
    
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">loss</span>
    
        <span class="k">def</span> <span class="nf">gradient_update</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            TODO:UNTESTED</span>
<span class="sd">    </span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">quadratic_term_gradient</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span>
            <span class="n">linear_term_gradient</span> <span class="o">=</span> <span class="n">YM</span>
            <span class="k">if</span> <span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span><span class="p">:</span>
                <span class="n">linear_term_gradient</span> <span class="o">=</span> <span class="n">linear_term_gradient</span> <span class="o">-</span> <span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">prior_x_mode</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">quadratic_term_gradient</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="p">(</span><span class="n">linear_term_gradient</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">Ynorm</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="n">quadratic_term_gradient</span> <span class="o">-</span> <span class="n">linear_term_gradient</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">loss</span>
            
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
            <span class="n">X_prev</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">update_alg</span> <span class="o">==</span> <span class="s1">&#39;mu&#39;</span><span class="p">:</span>
                <span class="c1"># TODO: it seems like loss might not always decrease...</span>
                <span class="n">X</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">YM</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">Ynorm</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="n">numerator</span> <span class="o">=</span> <span class="n">YM</span>
                <span class="n">denominator</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span>
                <span class="k">if</span> <span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span><span class="p">:</span>
                    <span class="c1"># see sklearn.decomposition.NMF</span>
                    <span class="n">loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="n">denominator</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="kc">None</span><span class="p">])</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="n">prior_x_mode</span><span class="p">:</span>
                    <span class="k">pass</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="k">assert</span> <span class="n">loss</span> <span class="o">&lt;=</span> <span class="n">loss_prev</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span> <span class="p">(</span><span class="n">loss_prev</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">loss</span><span class="p">)</span>
                <span class="n">multiplicative_factor</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
                <span class="n">X</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">multiplicative_factor</span><span class="p">)</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
    
                <span class="c1"># X, loss = multiplicative_update(X_prev)</span>
            <span class="k">elif</span> <span class="n">update_alg</span> <span class="o">==</span> <span class="s1">&#39;gd&#39;</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">gradient_update</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    
            <span class="n">dX</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">X_prev</span> <span class="o">-</span> <span class="n">X</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">do_stop</span> <span class="o">=</span> <span class="n">dX</span> <span class="o">&lt;</span> <span class="n">tol</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">do_stop</span><span class="p">:</span>
                <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Updating weight w/o nbrs: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                    <span class="sa">f</span><span class="s1">&#39;%δloss = </span><span class="si">{</span><span class="p">(</span><span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                    <span class="sa">f</span><span class="s1">&#39;%δX = </span><span class="si">{</span><span class="n">dX</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="p">)</span>
            <span class="n">loss_prev</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="k">if</span> <span class="n">do_stop</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">X</span></div>
    
<div class="viewcode-block" id="EmbeddingOptimizer.estimate_weight_wnbr"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingOptimizer.estimate_weight_wnbr">[docs]</a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">estimate_weight_wnbr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sigma_yx</span><span class="p">,</span> <span class="n">prior_x_mode</span><span class="p">,</span> <span class="n">prior_x</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">update_alg</span><span class="o">=</span><span class="s1">&#39;nesterov&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate updated weights taking neighbor-neighbor interactions into account.</span>
<span class="sd">    </span>
<span class="sd">        The optimization for all variables</span>
<span class="sd">        min 1/2σ^2 || Y - diag(S) Z MT ||_2^2 + lam || S ||_1 + sum_{ij in E} ziT Σx-1 zj</span>
<span class="sd">    </span>
<span class="sd">        for s_i</span>
<span class="sd">        min 1/2σ^2 || y - M z s ||_2^2 + lam s</span>
<span class="sd">        s* = max(0, ( yT M z / σ^2 - lam ) / ( zT MT M z / σ^2) )</span>
<span class="sd">    </span>
<span class="sd">        for Z</span>
<span class="sd">        min 1/2σ^2 || Y - diag(S) Z MT ||_2^2 + sum_{ij in E} ziT Σx-1 zj</span>
<span class="sd">        grad_i = MT M z s^2 / σ^2 - MT y s / σ^2 + sum_{j in Ei} Σx-1 zj</span>
<span class="sd">    </span>
<span class="sd">        TODO: Try projected Newton&#39;s method.</span>
<span class="sd">        TM: Inverse is precomputed once, and projection is cheap. Not sure if it works theoretically</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Precomputing quantities</span>
        <span class="n">MTM</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">M</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">YM</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">@</span> <span class="n">M</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">Ynorm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yx</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">base_step_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">MTM</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">S</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        
        <span class="n">E_adjacency_list</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]</span>
        <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;adjacency_matrix&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
        <span class="n">Sigma_x_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_optimizer</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
    
        <span class="k">def</span> <span class="nf">get_adjacency_matrix</span><span class="p">(</span><span class="n">adjacency_list</span><span class="p">):</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">adjacency_list</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">e</span><span class="p">]</span>
            <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">edges</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">adjacency_list</span><span class="p">),</span> <span class="n">N</span><span class="p">],</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">adjacency_matrix</span>
    
        <span class="k">def</span> <span class="nf">update_s</span><span class="p">():</span>
            <span class="n">S</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">YM</span> <span class="o">*</span> <span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span><span class="p">:</span>
                <span class="c1"># TODO: why divide by two?</span>
                <span class="n">S</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">prior_x_mode</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    
            <span class="n">denominator</span> <span class="o">=</span> <span class="p">((</span><span class="n">Z</span> <span class="o">@</span> <span class="n">MTM</span><span class="p">)</span> <span class="o">*</span> <span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">S</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">denominator</span><span class="p">)</span>
            <span class="n">S</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    
        <span class="c1"># Debugging for loss of M</span>
        <span class="k">def</span> <span class="nf">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="n">quadratic_factor_grad</span> <span class="o">=</span> <span class="n">M</span> <span class="o">@</span> <span class="n">quadratic_factor</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">quadratic_factor_grad</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">quadratic_factor_grad</span>
            <span class="n">linear_term_grad</span> <span class="o">=</span> <span class="n">linear_term</span>
            <span class="n">loss</span> <span class="o">-=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">linear_term_grad</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">-=</span> <span class="n">linear_term_grad</span>
            
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">constant</span>
            <span class="n">loss</span> <span class="o">/=</span> <span class="mi">2</span>
    
            <span class="k">if</span> <span class="n">M_constraint</span> <span class="o">==</span> <span class="s1">&#39;simplex&#39;</span><span class="p">:</span>
                <span class="n">grad</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">grad</span>
        
        <span class="k">def</span> <span class="nf">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad</span><span class="p">,</span> <span class="n">linear</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">Z_batch</span> <span class="o">@</span> <span class="n">quad</span><span class="p">)</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">S_batch</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">Z_batch</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">t</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">linear</span>
            <span class="n">f</span> <span class="o">-=</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">Z_batch</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">g</span> <span class="o">-=</span> <span class="n">t</span>
            <span class="n">g</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            
            <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">g</span>
    
        <span class="k">def</span> <span class="nf">update_z_gd</span><span class="p">(</span><span class="n">Z</span><span class="p">):</span>
            <span class="n">step_size</span> <span class="o">=</span> <span class="n">base_step_size</span> <span class="o">/</span> <span class="n">S</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">IndependentSet</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
                <span class="n">step_size_scale</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">quad_batch</span> <span class="o">=</span> <span class="n">MTM</span>
                <span class="n">linear_batch</span> <span class="o">=</span> <span class="n">YM</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">S</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span>
                <span class="n">Z_batch</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">S_batch</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">step_size_batch</span> <span class="o">=</span> <span class="n">step_size</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad_batch</span><span class="p">,</span> <span class="n">linear_batch</span><span class="p">)</span>
                <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="n">Z_batch_new</span> <span class="o">=</span> <span class="n">Z_batch</span> <span class="o">-</span> <span class="n">step_size_batch</span> <span class="o">*</span> <span class="n">step_size_scale</span> <span class="o">*</span> <span class="n">grad</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">project2simplex</span><span class="p">(</span><span class="n">Z_batch_new</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">Z_batch_new</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">Z_batch_new</span> <span class="o">=</span> <span class="n">result</span>
                    <span class="n">dZ</span> <span class="o">=</span> <span class="n">Z_batch_new</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">func_new</span><span class="p">,</span> <span class="n">grad_new</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch_new</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad_batch</span><span class="p">,</span> <span class="n">linear_batch</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">func_new</span> <span class="o">&lt;</span> <span class="n">func</span><span class="p">:</span>
                        <span class="n">Z_batch</span> <span class="o">=</span> <span class="n">Z_batch_new</span>
                        <span class="n">func</span> <span class="o">=</span> <span class="n">func_new</span>
                        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_new</span>
                        <span class="n">step_size_scale</span> <span class="o">*=</span> <span class="mf">1.1</span>
                        <span class="k">continue</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">step_size_scale</span> <span class="o">*=</span> <span class="mf">.5</span>
                    <span class="k">if</span> <span class="n">dZ</span> <span class="o">&lt;</span> <span class="n">tol</span> <span class="ow">or</span> <span class="n">step_size_scale</span> <span class="o">&lt;</span> <span class="mf">.5</span><span class="p">:</span> <span class="k">break</span>
                <span class="k">assert</span> <span class="n">step_size_scale</span> <span class="o">&gt;</span> <span class="mf">.1</span>
                <span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">Z_batch</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Updating Z w/ nbrs via line search: lr=</span><span class="si">{</span><span class="n">step_size_scale</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
            <span class="k">return</span> <span class="n">Z</span>
    
        <span class="k">def</span> <span class="nf">update_z_gd_nesterov</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Updating Z w/ nbrs via Nesterov GD&#39;</span><span class="p">)</span>
           
            <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">MTM</span><span class="p">,</span> <span class="n">YM</span> <span class="o">*</span> <span class="n">S</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">IndependentSet</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
                <span class="n">quad_batch</span> <span class="o">=</span> <span class="n">MTM</span>
                <span class="n">linear_batch_spatial</span> <span class="o">=</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span>
                <span class="n">Z_batch</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                <span class="n">S_batch</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                    
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">NesterovGD</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">base_step_size</span> <span class="o">/</span> <span class="n">S_batch</span><span class="o">.</span><span class="n">square</span><span class="p">())</span>
                <span class="n">ppbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i_iter</span> <span class="ow">in</span> <span class="n">ppbar</span><span class="p">:</span>
                    <span class="n">update_s</span><span class="p">()</span> <span class="c1"># TODO: update S_batch directly</span>
                    <span class="n">S_batch</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
                    <span class="n">linear_batch</span> <span class="o">=</span> <span class="n">linear_batch_spatial</span> <span class="o">+</span> <span class="n">YM</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">S_batch</span>
                    <span class="k">if</span> <span class="n">i_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad_batch</span><span class="p">,</span> <span class="n">linear_batch</span><span class="p">)</span>
                        <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">MTM</span><span class="p">,</span> <span class="n">YM</span> <span class="o">*</span> <span class="n">S</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="n">NesterovGD</span><span class="o">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="n">base_step_size</span> <span class="o">/</span> <span class="n">S_batch</span><span class="o">.</span><span class="n">square</span><span class="p">()</span> <span class="c1"># TM: I think this converges as s converges</span>
                    <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad_batch</span><span class="p">,</span> <span class="n">linear_batch</span><span class="p">)</span>
                    <span class="c1"># grad_limit = torch.quantile(torch.abs(grad), 0.9)</span>
                    <span class="c1"># max_before = torch.max(torch.abs(grad))</span>
                    <span class="c1"># grad.clamp_(min=-grad_limit, max=grad_limit)</span>
                    <span class="c1"># max_after = torch.max(torch.abs(grad))</span>
                    <span class="n">Z_batch_prev</span> <span class="o">=</span> <span class="n">Z_batch</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="n">Z_batch_copy</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
                    <span class="c1"># if max(torch.linalg.norm(Z_batch_copy, ord=1, axis=1)) &gt; 1000:</span>
                    <span class="c1">#     print(f&quot;L1 norm of Z_batch_copy: {torch.linalg.norm(Z_batch_copy, ord=1, axis=1)}&quot;)</span>
                    <span class="c1">#     print(f&quot;Max L1 norm of Z_batch_copy: {max(torch.linalg.norm(Z_batch_copy, ord=1, axis=1))}&quot;)</span>
                    <span class="c1">#     print(f&quot;L2 norm of Z_batch_copy: {torch.linalg.norm(Z_batch_copy, ord=2, axis=1)}&quot;)</span>
                    <span class="c1">#     print(f&quot;Max L2 norm of Z_batch_copy: {max(torch.linalg.norm(Z_batch_copy, ord=2, axis=1))}&quot;)</span>
                    <span class="c1">#     print(f&quot;Grad: {grad}&quot;)</span>
                    <span class="c1">#     print(f&quot;Grad max before: {max_before}&quot;)</span>
                    <span class="c1">#     print(f&quot;grad limit:{grad_limit}&quot;)</span>
                    <span class="c1">#     print(f&quot;Grad max after: {max_after}&quot;)</span>
                    <span class="n">Z_batch</span> <span class="o">=</span> <span class="n">project2simplex</span><span class="p">(</span><span class="n">Z_batch_copy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">)</span>
                    <span class="n">dZ</span> <span class="o">=</span> <span class="p">(</span><span class="n">Z_batch_prev</span> <span class="o">-</span> <span class="n">Z_batch</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">Z_batch</span>
                    <span class="n">ppbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;func=</span><span class="si">{</span><span class="n">func</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, dZ=</span><span class="si">{</span><span class="n">dZ</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">dZ</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="n">ppbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                
                <span class="n">Z</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">Z_batch</span>
                <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z_batch</span><span class="p">,</span> <span class="n">S_batch</span><span class="p">,</span> <span class="n">quad_batch</span><span class="p">,</span> <span class="n">linear_batch</span><span class="p">)</span>
                <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">MTM</span><span class="p">,</span> <span class="n">YM</span> <span class="o">*</span> <span class="n">S</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span> <span class="o">/</span><span class="mi">2</span> <span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Z loss: </span><span class="si">{</span><span class="n">func</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">func</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">calc_func_grad</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">MTM</span><span class="p">,</span> <span class="n">YM</span> <span class="o">*</span> <span class="n">S</span> <span class="o">-</span> <span class="n">get_adjacency_matrix</span><span class="p">(</span><span class="n">E_adjacency_list</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Z final loss: </span><span class="si">{</span><span class="n">func</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
            <span class="k">return</span> <span class="n">Z</span>
    
        <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">():</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">*</span> <span class="n">S</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">MTM</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">YM</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">Ynorm</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">+=</span> <span class="n">prior_x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">prior_x_mode</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    
            <span class="k">if</span> <span class="n">Sigma_x_inv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">+=</span> <span class="p">((</span><span class="n">adjacency_matrix</span> <span class="o">@</span> <span class="n">Z</span><span class="p">)</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="c1"># assert loss &lt;= loss_prev, (loss_prev, loss)</span>
            <span class="k">return</span> <span class="n">loss</span>
    
        <span class="c1"># TM: consider combine compute_loss and update_z to remove a call to torch.sparse.mm</span>
        <span class="c1"># TM: the above idea is not practical if we update only a subset of nodes each time</span>
    
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Updating weight w/ neighbors&#39;</span><span class="p">)</span>
    
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="n">update_s</span><span class="p">()</span>
            <span class="n">Z_prev</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="c1"># We may use Nesterov first and then vanilla GD in later iterations</span>
            <span class="c1"># update_z_mu(Z)</span>
            <span class="c1"># update_z_gd(Z)</span>
            <span class="k">if</span> <span class="n">update_alg</span> <span class="o">==</span> <span class="s2">&quot;gd&quot;</span><span class="p">:</span>
                <span class="n">Z</span> <span class="o">=</span> <span class="n">update_z_gd</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">update_alg</span> <span class="o">==</span> <span class="s2">&quot;nesterov&quot;</span><span class="p">:</span>
                <span class="n">Z</span> <span class="o">=</span> <span class="n">update_z_gd_nesterov</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
    
            <span class="n">loss_prev</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">()</span>
            <span class="n">dloss</span> <span class="o">=</span> <span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span>
            <span class="n">dZ</span> <span class="o">=</span> <span class="p">(</span><span class="n">Z_prev</span> <span class="o">-</span> <span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;Updating weight w/ neighbors: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;δloss = </span><span class="si">{</span><span class="n">dloss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;δZ = </span><span class="si">{</span><span class="n">dZ</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">dZ</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
        <span class="n">X_final</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">*</span> <span class="n">S</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">X_final</span></div></div>

<div class="viewcode-block" id="EmbeddingState"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingState">[docs]</a><span class="k">class</span> <span class="nc">EmbeddingState</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Collections of cell embeddings for all ST replicates.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        K: embedding dimension:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">datasets</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">SpiceMixDataset</span><span class="p">],</span> <span class="n">initial_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span> <span class="o">=</span> <span class="n">initial_context</span> <span class="k">if</span> <span class="n">initial_context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="n">num_cells</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">replicate_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_cells</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">replicate_embeddings</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">replicate_embeddings</span><span class="p">)</span>

<div class="viewcode-block" id="EmbeddingState.normalize"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.EmbeddingState.normalize">[docs]</a>    <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_key</span><span class="o">=</span><span class="s2">&quot;normalized_X&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Normalize embeddings per each cell.</span>
<span class="sd">        </span>
<span class="sd">        This step helps to make cell embeddings comparable, and facilitates downstream tasks like clustering.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: implement</span>

        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obsm</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must initialize embeddings before running normalizing them.&quot;</span><span class="p">)</span>

            <span class="n">dataset</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;normalized_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">])</span>
            <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;normalized_X&quot;</span><span class="p">)</span></div></div>

<div class="viewcode-block" id="ParameterOptimizer"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer">[docs]</a><span class="k">class</span> <span class="nc">ParameterOptimizer</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Optimizer and state for SpiceMix parameters.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">prior_x_modes</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span>
            <span class="n">spatial_affinity_regularization_power</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">spatial_affinity_scaling</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">lambda_Sigma_x_inv</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
            <span class="n">spatial_affinity_mode</span><span class="o">=</span><span class="s2">&quot;shared lookup&quot;</span><span class="p">,</span>
            <span class="n">metagene_mode</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span>
            <span class="n">lambda_M</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">lambda_Sigma_bar</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">M_constraint</span><span class="o">=</span><span class="s2">&quot;simplex&quot;</span><span class="p">,</span>
            <span class="n">sigma_yx_inv_mode</span><span class="o">=</span><span class="s2">&quot;separate&quot;</span><span class="p">,</span>
            <span class="n">initial_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">context</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_mode</span> <span class="o">=</span> <span class="n">spatial_affinity_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ys</span> <span class="o">=</span> <span class="n">Ys</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yx_inv_mode</span> <span class="o">=</span> <span class="n">sigma_yx_inv_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_Sigma_bar</span> <span class="o">=</span> <span class="n">lambda_Sigma_bar</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_Sigma_x_inv</span> <span class="o">=</span> <span class="n">lambda_Sigma_x_inv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_M</span> <span class="o">=</span> <span class="n">lambda_M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">=</span> <span class="n">metagene_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span> <span class="o">=</span> <span class="n">M_constraint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_x_modes</span> <span class="o">=</span> <span class="n">prior_x_modes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span> <span class="o">=</span> <span class="n">initial_context</span> <span class="k">if</span> <span class="n">initial_context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_regularization_power</span> <span class="o">=</span> <span class="n">spatial_affinity_regularization_power</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span> <span class="o">=</span> <span class="n">MetageneState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span><span class="p">,</span> <span class="n">M_constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span><span class="p">,</span> <span class="n">initial_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span> <span class="o">=</span> <span class="n">SpatialAffinityState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="n">spatial_affinity_scaling</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_mode</span><span class="p">,</span> <span class="n">initial_context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">prior_x_mode</span> <span class="o">==</span> <span class="s1">&#39;exponential shared fixed&#39;</span> <span class="k">for</span> <span class="n">prior_x_mode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_x_modes</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior_xs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">),)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">))]</span>
        <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="n">prior_x_mode</span> <span class="o">==</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">prior_x_mode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_x_modes</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior_xs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">),)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">))</span>

<div class="viewcode-block" id="ParameterOptimizer.link"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.link">[docs]</a>    <span class="k">def</span> <span class="nf">link</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_optimizer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Link to embedding_optimizer.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span> <span class="o">=</span> <span class="n">embedding_optimizer</span></div>
       
<div class="viewcode-block" id="ParameterOptimizer.scale_metagenes"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.scale_metagenes">[docs]</a>    <span class="k">def</span> <span class="nf">scale_metagenes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">norm_axis</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># norm_axis = int(self.metagene_mode == &quot;differential&quot;)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span> <span class="o">==</span> <span class="s1">&#39;simplex&#39;</span><span class="p">:</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="o">.</span><span class="n">metagenes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">norm_axis</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span> <span class="o">==</span> <span class="s1">&#39;unit_sphere&#39;</span><span class="p">:</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="o">.</span><span class="n">metagenes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">norm_axis</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="o">.</span><span class="n">metagenes</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">group_index</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">replicate_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span><span class="o">.</span><span class="n">embedding_state</span><span class="o">.</span><span class="n">embeddings</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">==</span> <span class="s2">&quot;differential&quot;</span><span class="p">:</span>
                    <span class="n">replicate_scale_factor</span> <span class="o">=</span> <span class="n">scale_factor</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
                    <span class="n">replicate_embedding</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">replicate_scale_factor</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">group_scale_factor</span> <span class="o">=</span> <span class="n">scale_factor</span><span class="p">[</span><span class="n">group_index</span><span class="p">]</span>
                    <span class="n">replicate_embedding</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">group_scale_factor</span><span class="p">)</span></div>

<div class="viewcode-block" id="ParameterOptimizer.estimate_Sigma_x_inv"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.estimate_Sigma_x_inv">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_Sigma_x_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">Sigma_x_inv_bar</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">constraint</span><span class="o">=</span><span class="s2">&quot;clamp&quot;</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Optimize Sigma_x_inv parameters.</span>
<span class="sd">    </span>
<span class="sd">       </span>
<span class="sd">        Differential mode:</span>
<span class="sd">        grad =  ... + λ_Sigma_x_inv ( Sigma_x_inv - Sigma_x_inv_bar )</span>
<span class="sd">    </span>
<span class="sd">        Args:</span>
<span class="sd">            Xs: list of latent expression embeddings for each FOV.</span>
<span class="sd">            Sigma_x_inv: previous estimate of Σx-1</span>
<span class="sd">    </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span> <span class="k">for</span> <span class="p">(</span><span class="n">use_replicate</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">replicate_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="n">use_replicate</span><span class="p">]</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
        <span class="n">spatial_flags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>

        <span class="n">num_edges_per_fov</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]))</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">u</span> <span class="k">for</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">spatial_flags</span><span class="p">)):</span>
            <span class="k">return</span>
    
        <span class="n">linear_term_coefficient</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Sigma_x_inv</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">size_factors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">Xs</span> <span class="p">]</span>
        <span class="n">Zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">size_factor</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">size_factor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">size_factors</span><span class="p">)]</span>
        <span class="n">nus</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># sum of neighbors&#39; z</span>
        <span class="n">weighted_total_cells</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">Z</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">use_spatial</span><span class="p">,</span> <span class="n">beta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Zs</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">spatial_flags</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">):</span>
            <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obsp</span><span class="p">[</span><span class="s2">&quot;adjacency_matrix&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
            <span class="n">adjacency_list</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">use_spatial</span><span class="p">:</span>
                <span class="n">nu</span> <span class="o">=</span> <span class="n">adjacency_matrix</span> <span class="o">@</span> <span class="n">Z</span>
                <span class="n">linear_term_coefficient</span> <span class="o">=</span> <span class="n">linear_term_coefficient</span><span class="o">.</span><span class="n">addmm_</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nu</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">nus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span>
            <span class="n">weighted_total_cells</span> <span class="o">+=</span> <span class="n">beta</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">adjacency_list</span><span class="p">))</span>
            <span class="k">del</span> <span class="n">Z</span><span class="p">,</span> <span class="n">adjacency_matrix</span>
        <span class="c1"># linear_term_coefficient = (linear_term_coefficient + linear_term_coefficient.T) / 2 # should be unnecessary as long as adjacency_list is symmetric</span>
    
        <span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
   
        <span class="n">loss_prev</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Updating Σx-1&#39;</span><span class="p">)</span>
        <span class="n">Sigma_x_inv_best</span><span class="p">,</span> <span class="n">loss_best</span><span class="p">,</span> <span class="n">epoch_best</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">dSigma_x_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">early_stop_epoch_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
            <span class="c1"># Compute loss </span>
            <span class="n">linear_term</span> <span class="o">=</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">linear_term_coefficient</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">Sigma_x_inv_bar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">regularization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_Sigma_bar</span> <span class="o">*</span> <span class="p">(</span><span class="n">Sigma_x_inv_bar</span> <span class="o">-</span> <span class="n">Sigma_x_inv</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">weighted_total_cells</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regularization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>

            <span class="n">regularization</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_Sigma_x_inv</span> <span class="o">*</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_regularization_power</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">weighted_total_cells</span> <span class="o">/</span> <span class="mi">2</span>
            
            <span class="n">log_partition_function</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">Z</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">beta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Zs</span><span class="p">,</span> <span class="n">nus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">nu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
                <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">Sigma_x_inv</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
                <span class="n">eta</span> <span class="o">=</span> <span class="n">nu</span> <span class="o">@</span> <span class="n">Sigma_x_inv</span>
                <span class="n">logZ</span> <span class="o">=</span> <span class="n">integrate_of_exponential_over_simplex</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
                <span class="n">log_partition_function</span> <span class="o">+=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">logZ</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">linear_term</span> <span class="o">+</span> <span class="n">regularization</span> <span class="o">+</span> <span class="n">log_partition_function</span><span class="p">)</span> <span class="o">/</span> <span class="n">weighted_total_cells</span>
   
            <span class="c1"># print(f&quot;total loss {loss}&quot;)</span>
            <span class="c1"># print(f&quot;linear term {linear_term}&quot;)</span>
            <span class="c1"># print(f&quot;regularization {regularization}&quot;)</span>
            <span class="c1"># print(f&quot;log_partition_function {log_partition_function}&quot;)</span>
            <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">loss_best</span><span class="p">:</span>
                <span class="n">Sigma_x_inv_best</span> <span class="o">=</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">loss_best</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">epoch_best</span> <span class="o">=</span> <span class="n">epoch</span>
    
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
    
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">Sigma_x_inv_prev</span> <span class="o">=</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">grad</span> <span class="o">+</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">constraint</span> <span class="o">==</span> <span class="s2">&quot;clamp&quot;</span><span class="p">:</span>
                    <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="o">.</span><span class="n">scaling</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="o">.</span><span class="n">scaling</span><span class="p">)</span>
            <span class="c1"># with torch.no_grad():</span>
            <span class="c1">#   Sigma_x_inv -= Sigma_x_inv.mean()</span>
    
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">dloss</span> <span class="o">=</span> <span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span>
            <span class="n">loss_prev</span> <span class="o">=</span> <span class="n">loss</span>
    
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">dSigma_x_inv</span> <span class="o">=</span> <span class="n">Sigma_x_inv_prev</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">Sigma_x_inv</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;Updating Σx-1: loss = </span><span class="si">{</span><span class="n">dloss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;δΣx-1 = </span><span class="si">{</span><span class="n">dSigma_x_inv</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;Σx-1 range = </span><span class="si">{</span><span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1"> ~ </span><span class="si">{</span><span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">)</span>
    
            <span class="k">if</span> <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-4</span> <span class="ow">and</span> <span class="n">dSigma_x_inv</span> <span class="o">&lt;</span> <span class="mf">1e-4</span><span class="p">:</span>
                <span class="n">early_stop_epoch_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">early_stop_epoch_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">early_stop_epoch_count</span> <span class="o">&gt;=</span> <span class="mi">10</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">epoch_best</span> <span class="o">+</span> <span class="mi">100</span><span class="p">:</span>
                <span class="k">break</span>
    
        <span class="n">Sigma_x_inv</span> <span class="o">=</span> <span class="n">Sigma_x_inv_best</span>
        <span class="n">Sigma_x_inv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
       
        <span class="k">return</span> <span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">weighted_total_cells</span></div>

<div class="viewcode-block" id="ParameterOptimizer.update_spatial_affinity"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.update_spatial_affinity">[docs]</a>    <span class="k">def</span> <span class="nf">update_spatial_affinity</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_mode</span> <span class="o">==</span> <span class="s2">&quot;shared lookup&quot;</span><span class="p">:</span>
                <span class="n">replicate_mask</span> <span class="o">=</span>  <span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">group_replicates</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">]</span>
                <span class="n">first_dataset_name</span> <span class="o">=</span> <span class="n">group_replicates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">Sigma_x_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="p">[</span><span class="n">first_dataset_name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">first_dataset_name</span><span class="p">]</span>
                <span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_Sigma_x_inv</span><span class="p">(</span><span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="p">[</span><span class="n">first_dataset_name</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">Sigma_x_inv</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_mode</span> <span class="o">==</span> <span class="s2">&quot;differential lookup&quot;</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                    <span class="n">replicate_mask</span> <span class="o">=</span>  <span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">dataset_name</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">]</span>
                    <span class="n">Sigma_x_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="p">[</span><span class="n">dataset_name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">])</span>
                    <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">dataset_name</span><span class="p">]</span>
                    <span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_Sigma_x_inv</span><span class="p">(</span><span class="n">Sigma_x_inv</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">Sigma_x_inv_bar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">)</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="c1"># print(self.spatial_affinity_state[dataset.name][0])</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">Sigma_x_inv</span></div>
                        <span class="c1"># print(Sigma_x_inv[0])</span>

<div class="viewcode-block" id="ParameterOptimizer.update_metagenes"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.update_metagenes">[docs]</a>    <span class="k">def</span> <span class="nf">update_metagenes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">==</span> <span class="s2">&quot;shared&quot;</span><span class="p">:</span>
                <span class="n">first_dataset_name</span> <span class="o">=</span> <span class="n">group_replicates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">replicate_mask</span> <span class="o">=</span>  <span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">group_replicates</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">]</span>
                <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">first_dataset_name</span><span class="p">]</span>
                <span class="n">updated_M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_M</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">dataset_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_M</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">==</span> <span class="s2">&quot;differential&quot;</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                    <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                    <span class="n">replicate_mask</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">),</span> <span class="kc">False</span><span class="p">)</span>
                    <span class="n">replicate_mask</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_M</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">,</span> <span class="n">M_bar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="o">.</span><span class="n">M_bar</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="o">.</span><span class="n">reaverage</span><span class="p">()</span></div>

<div class="viewcode-block" id="ParameterOptimizer.estimate_M"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.estimate_M">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_M</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">replicate_mask</span><span class="p">,</span>
            <span class="n">M_bar</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">backend_algorithm</span><span class="o">=</span><span class="s1">&#39;gd Nesterov&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Optimize metagene parameters.</span>
<span class="sd">    </span>
<span class="sd">        M is shared across all replicates.</span>
<span class="sd">        min || Y - X MT ||_2^2 / (2 σ_yx^2)</span>
<span class="sd">        s.t. || Mk ||_p = 1</span>
<span class="sd">        grad = (M XT X - YT X) / (σ_yx^2)</span>
<span class="sd">    </span>
<span class="sd">        Each replicate may have a slightly different M</span>
<span class="sd">        min || Y - X MT ||_2^2 / (2 σ_yx^2) + || M - M_bar ||_2^2 λ_M / 2</span>
<span class="sd">        s.t. || Mk ||_p = 1</span>
<span class="sd">        grad = ( M XT X - YT X ) / ( σ_yx^2 ) + λ_M ( M - M_bar )</span>
<span class="sd">    </span>
<span class="sd">        Args:</span>
<span class="sd">            M: current estimate of metagene parameters</span>
<span class="sd">            betas: weight of each FOV in optimization scheme</span>
<span class="sd">            context: context ith which to create PyTorch tensor</span>
<span class="sd">            n_epochs: number of epochs </span>
<span class="sd">    </span>
<span class="sd">        Returns:</span>
<span class="sd">            Updated estimate of metagene parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">quadratic_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
        <span class="n">linear_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="c1"># TODO: replace below (and any reference to dataset)</span>
        
        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span> <span class="k">for</span> <span class="p">(</span><span class="n">use_replicate</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">replicate_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="n">use_replicate</span><span class="p">]</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
        <span class="n">Ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">Y</span> <span class="k">for</span> <span class="p">(</span><span class="n">use_replicate</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">replicate_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ys</span><span class="p">)</span> <span class="k">if</span> <span class="n">use_replicate</span><span class="p">]</span>
        <span class="n">sigma_yxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dataset</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s2">&quot;sigma_yx&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">])</span>
        <span class="n">scaled_betas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">replicate_mask</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma_yxs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># ||Y||_2^2</span>
        <span class="n">constant_magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">Ys</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    
        <span class="n">constant</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">])</span> <span class="o">*</span> <span class="n">scaled_betas</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">regularization</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_xs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">datasets</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">sigma_yx</span><span class="p">,</span> <span class="n">scaled_beta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">sigma_yxs</span><span class="p">,</span> <span class="n">scaled_betas</span><span class="p">):</span>
            <span class="c1"># X_c^TX_c</span>
            <span class="n">quadratic_factor</span><span class="o">.</span><span class="n">addmm_</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">scaled_beta</span><span class="p">)</span>
            <span class="c1"># MX_c^TY_c</span>
            <span class="n">linear_term</span><span class="o">.</span><span class="n">addmm_</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">scaled_beta</span><span class="p">)</span>
    
        <span class="c1"># if self.lambda_M &gt; 0 and M_bar is not None:</span>
        <span class="c1">#     quadratic_factor.diagonal().add_(self.lambda_M)</span>
        <span class="c1">#     linear_term += self.lambda_M * M_bar</span>
        <span class="n">differential_regularization_quadratic_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
        <span class="n">differential_regularization_linear_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_M</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">M_bar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">differential_regularization_quadratic_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_M</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
            <span class="n">differential_regularization_linear_term</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_M</span> <span class="o">*</span> <span class="n">M_bar</span>
        <span class="c1">#     quadratic_factor.diagonal().add_(self.lambda_M)</span>
        <span class="c1">#     linear_term += self.lambda_M * M_bar</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DTYPE: </span><span class="si">{</span><span class="n">quadratic_factor</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max eigenvalue before : </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenvalue before : </span><span class="si">{</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max eigenvalue after : </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span> <span class="o">+</span> <span class="n">differential_regularization_quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenvalue after : </span><span class="si">{</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span> <span class="o">+</span> <span class="n">differential_regularization_quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Difference: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span> <span class="o">+</span> <span class="n">differential_regularization_quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All differences: </span><span class="si">{</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span> <span class="o">+</span> <span class="n">differential_regularization_quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span> <span class="o">-</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Linear term: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">linear_term</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Regularization linear term: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">differential_regularization_linear_term</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Linear regularization term ratio: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">differential_regularization_linear_term</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">linear_term</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">loss_prev</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Updating M&#39;</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    
        <span class="k">def</span> <span class="nf">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">quadratic_factor_grad</span> <span class="o">=</span> <span class="n">M</span> <span class="o">@</span> <span class="p">(</span><span class="n">quadratic_factor</span> <span class="o">+</span> <span class="n">differential_regularization_quadratic_factor</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">quadratic_factor_grad</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M quadratic term: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">quadratic_factor_grad</span>
            <span class="n">linear_term_grad</span> <span class="o">=</span> <span class="n">linear_term</span> <span class="o">+</span> <span class="n">differential_regularization_linear_term</span>
            <span class="n">loss</span> <span class="o">-=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">linear_term_grad</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">-=</span> <span class="n">linear_term_grad</span>
        
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">constant</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">==</span> <span class="s2">&quot;differential&quot;</span><span class="p">:</span>
                <span class="n">differential_regularization_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">M</span> <span class="o">@</span> <span class="n">differential_regularization_quadratic_factor</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">differential_regularization_linear_term</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_M</span> <span class="o">*</span> <span class="p">(</span><span class="n">M_bar</span> <span class="o">*</span> <span class="n">M_bar</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="c1"># regularization_term = torch.sum(torch.Tensor([(regularizer[0] * X).sum() for regularizer, X in zip(regularization, Xs)]))</span>
            <span class="c1"># loss += regularization_term</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="c1"># print(f&quot;M regularization term: {regularization_term}&quot;)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_mode</span> <span class="o">==</span> <span class="s2">&quot;differential&quot;</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M differential regularization term: </span><span class="si">{</span><span class="n">differential_regularization_term</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M constant term: </span><span class="si">{</span><span class="n">constant</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M constant magnitude: </span><span class="si">{</span><span class="n">constant_magnitude</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">/=</span> <span class="mi">2</span>
    
    
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span> <span class="o">==</span> <span class="s1">&#39;simplex&#39;</span><span class="p">:</span>
                <span class="n">grad</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">grad</span>
        
        <span class="k">def</span> <span class="nf">estimate_M_nag</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Estimate M using Nesterov accelerated gradient descent.</span>
<span class="sd">    </span>
<span class="sd">            Args:</span>
<span class="sd">                M (torch.Tensor) : current estimate of meteagene parameters</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M NAG Initial Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
            <span class="n">step_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">NesterovGD</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">step_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
                <span class="n">loss_prev</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">M_prev</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    
                <span class="c1"># Update M</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">project_M</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    
                <span class="n">dloss</span> <span class="o">=</span> <span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span>
                <span class="n">dM</span> <span class="o">=</span> <span class="p">(</span><span class="n">M_prev</span> <span class="o">-</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">stop_criterion</span> <span class="o">=</span> <span class="n">dM</span> <span class="o">&lt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">5</span>
                <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;Updating M: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;%δloss = </span><span class="si">{</span><span class="n">dloss</span> <span class="o">/</span> <span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;δM = </span><span class="si">{</span><span class="n">dM</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
                        <span class="c1"># f&#39;lr={step_size_scale:.1e}&#39;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="k">break</span>
            
            <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M NAG Final Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
            <span class="k">return</span> <span class="n">M</span>
        
        <span class="k">if</span> <span class="n">backend_algorithm</span> <span class="o">==</span> <span class="s1">&#39;mu&#39;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">(((</span><span class="n">M</span> <span class="o">@</span> <span class="n">quadratic_factor</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">linear_term</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">constant</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">numerator</span> <span class="o">=</span> <span class="n">linear_term</span>
                <span class="n">denominator</span> <span class="o">=</span> <span class="n">M</span> <span class="o">@</span> <span class="n">quadratic_factor</span>
                <span class="n">multiplicative_factor</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
    
                <span class="n">M_prev</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="c1"># multiplicative_factor.clip_(max=10)</span>
                <span class="n">M</span> <span class="o">*=</span> <span class="n">multiplicative_factor</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">project_M</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span><span class="p">)</span>
                <span class="n">dM</span> <span class="o">=</span> <span class="n">M_prev</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">abs_</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
                <span class="n">stop_criterion</span> <span class="o">=</span> <span class="n">dM</span> <span class="o">&lt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">5</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;Updating M: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;%δloss = </span><span class="si">{</span><span class="p">(</span><span class="n">loss_prev</span> <span class="o">-</span> <span class="n">loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;δM = </span><span class="si">{</span><span class="n">dM</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="k">break</span>
    
        <span class="k">elif</span> <span class="n">backend_algorithm</span> <span class="o">==</span> <span class="s1">&#39;gd&#39;</span><span class="p">:</span>
            <span class="n">step_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">quadratic_factor</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">step_size_scale</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
            <span class="n">dM</span> <span class="o">=</span> <span class="n">dloss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
                <span class="n">M_new</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">step_size_scale</span><span class="p">)</span>
                <span class="n">M_new</span> <span class="o">=</span> <span class="n">project_M</span><span class="p">(</span><span class="n">M_new</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span><span class="p">)</span>
                <span class="n">loss_new</span><span class="p">,</span> <span class="n">grad_new</span> <span class="o">=</span> <span class="n">compute_loss_and_gradient</span><span class="p">(</span><span class="n">M_new</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">loss_new</span> <span class="o">&lt;</span> <span class="n">loss</span> <span class="ow">or</span> <span class="n">step_size_scale</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">dM</span> <span class="o">=</span> <span class="p">(</span><span class="n">M_new</span> <span class="o">-</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">dloss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">-</span> <span class="n">loss_new</span>
                    <span class="n">M</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">M_new</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_new</span>
                    <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_new</span>
                    <span class="n">step_size_scale</span> <span class="o">*=</span> <span class="mf">1.1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">step_size_scale</span> <span class="o">*=</span> <span class="mf">.5</span>
                    <span class="n">step_size_scale</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">step_size_scale</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
                <span class="n">stop_criterion</span> <span class="o">=</span> <span class="n">dM</span> <span class="o">&lt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">5</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;Updating M: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;%δloss = </span><span class="si">{</span><span class="n">dloss</span> <span class="o">/</span> <span class="n">loss</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;δM = </span><span class="si">{</span><span class="n">dM</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">, &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;lr=</span><span class="si">{</span><span class="n">step_size_scale</span><span class="si">:</span><span class="s1">.1e</span><span class="si">}</span><span class="s1">&#39;</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">:</span>
                    <span class="k">break</span>
    
        <span class="k">elif</span> <span class="n">backend_algorithm</span> <span class="o">==</span> <span class="s1">&#39;gd Nesterov&#39;</span><span class="p">:</span>
            <span class="n">M</span> <span class="o">=</span> <span class="n">estimate_M_nag</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
       
        <span class="k">return</span> <span class="n">M</span></div>

<div class="viewcode-block" id="ParameterOptimizer.update_sigma_yx"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.ParameterOptimizer.update_sigma_yx">[docs]</a>    <span class="k">def</span> <span class="nf">update_sigma_yx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update sigma_yx for each replicate.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">squared_terms</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_optimizer</span><span class="o">.</span><span class="n">embedding_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">Y</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)]</span>
        <span class="n">squared_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">squared_term</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s2">&quot;fro&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">squared_term</span> <span class="ow">in</span> <span class="n">squared_terms</span><span class="p">])</span>
        <span class="c1"># squared_loss = np.array([</span>
        <span class="c1">#     torch.linalg.norm(, ord=&#39;fro&#39;).item() ** 2</span>
        <span class="c1">#     for Y, X, dataset, replicate in zip(Ys, self.Xs, self.datasets, self.repli_list)</span>
        <span class="c1"># ])</span>
        <span class="n">num_replicates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span>
        <span class="n">sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dataset</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">size</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yx_inv_mode</span> <span class="o">==</span> <span class="s1">&#39;separate&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yxs</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">squared_loss</span> <span class="o">/</span> <span class="n">sizes</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yx_inv_mode</span> <span class="o">==</span> <span class="s1">&#39;average&#39;</span><span class="p">:</span>
            <span class="n">sigma_yx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span> <span class="n">squared_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span> <span class="n">sizes</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sigma_yxs</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_replicates</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">sigma_yx</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>

<div class="viewcode-block" id="MetageneState"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.MetageneState">[docs]</a><span class="k">class</span> <span class="nc">MetageneState</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;State to store metagene parameters during SpiceMixPlus optimization.</span>

<span class="sd">    Metagene state can be shared across replicates or maintained separately for each replicate.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        datasets: A reference to the list of SpiceMixDatasets that are being optimized.</span>
<span class="sd">        context: Parameters to define the context for PyTorch tensor instantiation.</span>
<span class="sd">        metagenes: A PyTorch tensor containing all metagene parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;shared&quot;</span><span class="p">,</span> <span class="n">M_constraint</span><span class="o">=</span><span class="s2">&quot;simplex&quot;</span><span class="p">,</span> <span class="n">initial_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span> <span class="o">=</span> <span class="n">initial_context</span> <span class="k">if</span> <span class="n">initial_context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span> <span class="o">=</span> <span class="n">M_constraint</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shared&quot;</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">num_genes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metagenes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">),</span> <span class="n">num_genes</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span><span class="p">),</span> <span class="n">group_metagenes</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagenes</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">group_metagenes</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;differential&quot;</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">num_genes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metagenes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">),</span> <span class="n">num_genes</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metagenes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">replicate_metagenes</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metagenes</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">replicate_metagenes</span><span class="p">)</span>
        
<div class="viewcode-block" id="MetageneState.reaverage"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.MetageneState.reaverage">[docs]</a>    <span class="k">def</span> <span class="nf">reaverage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Set M_bar to average of self.Ms (relatively memory efficient)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">project_M</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M_bar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_constraint</span><span class="p">)</span></div></div>

<div class="viewcode-block" id="SpatialAffinityState"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpatialAffinityState">[docs]</a><span class="k">class</span> <span class="nc">SpatialAffinityState</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">metagene_state</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;shared lookup&quot;</span><span class="p">,</span> <span class="n">initial_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metagene_state</span> <span class="o">=</span> <span class="n">metagene_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span> <span class="o">=</span> <span class="n">initial_context</span> <span class="k">if</span> <span class="n">initial_context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="n">scaling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">num_replicates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shared lookup&quot;</span><span class="p">:</span>
            <span class="n">metagene_affinities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">metagene_affinities</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;differential lookup&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                <span class="n">metagene_affinity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">metagene_affinity</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
            <span class="n">metagene_affinities</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># attention mechanism here</span>
            <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">metagene_affinities</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">])</span>

<div class="viewcode-block" id="SpatialAffinityState.initialize"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpatialAffinityState.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_embeddings</span><span class="p">,</span> <span class="n">scaling</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">use_spatial_info</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">use_spatial_info</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">num_replicates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span>
        <span class="n">Sigma_x_invs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_replicates</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">],</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_context</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">replicate</span><span class="p">,</span> <span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">initial_embedding</span><span class="p">,</span> <span class="n">is_spatial_replicate</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span> <span class="n">initial_embeddings</span><span class="p">,</span> <span class="n">use_spatial_info</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_spatial_replicate</span><span class="p">:</span>
                <span class="k">continue</span>
            
            <span class="n">adjacency_list</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;adjacency_list&quot;</span><span class="p">]</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">initial_embedding</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">adjacency_list</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">e</span><span class="p">])</span>
   
            <span class="n">x</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="n">edges</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[</span><span class="n">edges</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">y_std</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">x_std</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">corr</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">/</span> <span class="n">y_std</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">Sigma_x_invs</span><span class="p">[</span><span class="n">replicate</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">beta</span> <span class="o">*</span> <span class="n">corr</span>
    
        <span class="c1"># Symmetrizing and zero-centering Sigma_x_inv</span>
        <span class="n">Sigma_x_invs</span> <span class="o">=</span> <span class="p">(</span><span class="n">Sigma_x_invs</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">Sigma_x_invs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">Sigma_x_invs</span> <span class="o">-=</span> <span class="n">Sigma_x_invs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">Sigma_x_invs</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;shared lookup&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">first_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">shared_affinity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">first_dataset</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                        <span class="n">shared_affinity</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">Sigma_x_invs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>

                <span class="n">shared_affinity</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group_replicates</span><span class="p">))</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">shared_affinity</span><span class="p">],</span>
                    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">.9</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                        <span class="n">dataset</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s2">&quot;Sigma_x_inv&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="p">:</span> <span class="n">shared_affinity</span><span class="p">}</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span>
                
                <span class="c1"># # This optimizer retains its state throughout the optimization</span>
                <span class="c1"># self.optimizer = </span>
                <span class="c1"># optimizer = torch.optim.Adam(</span>
                <span class="c1">#     [self.__getitem__(dataset.name)],</span>
                <span class="c1">#     lr=1e-3,</span>
                <span class="c1">#     betas=(.5, .9),</span>
                <span class="c1"># )</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;differential lookup&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="o">+=</span> <span class="n">Sigma_x_invs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group_replicates</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">dataset_index</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>
                <span class="n">differential_affinity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="n">differential_affinity</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">Sigma_x_invs</span><span class="p">[</span><span class="n">dataset_index</span><span class="p">]</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">differential_affinity</span><span class="p">],</span>
                    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">.9</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">dataset</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s2">&quot;Sigma_x_inv&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span> <span class="p">:</span> <span class="n">differential_affinity</span><span class="p">}</span>
                <span class="n">dataset</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s2">&quot;Sigma_x_inv_bar&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">group_name</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">group_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">[</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span>
                
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
            <span class="c1">#TODO: initialize with gradient descent</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="SpatialAffinityState.reaverage"><a class="viewcode-back" href="../../spicemix.html#spicemix.components.SpatialAffinityState.reaverage">[docs]</a>    <span class="k">def</span> <span class="nf">reaverage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Set spatial_affinity_bar to average of self.spatial_affinitys (memory efficient)</span>
        <span class="k">for</span> <span class="n">group_name</span><span class="p">,</span> <span class="n">group_replicates</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">group_replicates</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_name</span><span class="p">]</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spatial_affinity_bar</span><span class="p">[</span><span class="n">group_names</span><span class="p">]</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group_replicates</span><span class="p">))</span></div></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Shahul Alam<br/>
  
      &copy; Copyright 2022, CMU.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>